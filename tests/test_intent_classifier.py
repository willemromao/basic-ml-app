import os
import sys
import pytest
import numpy as np
import yaml
import pandas as pd
import tensorflow as tf
from sklearn.metrics import classification_report, confusion_matrix
from dotenv import load_dotenv

# Adiciona o diretÃ³rio raiz ao sys.path para encontrar o mÃ³dulo
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# Importa o cÃ³digo fonte que estamos testando
from intent_classifier import IntentClassifier, Config

# --- Fixtures (Contextos de Teste) ---

@pytest.fixture(scope="session")
def paths():
    """Fornece caminhos para arquivos de dados de teste, pulando se nÃ£o encontrados."""
    test_dir = os.path.dirname(__file__)
    project_root = os.path.abspath(os.path.join(test_dir, ".."))
    
    # Caminhos baseados na estrutura de arquivos original
    examples_path = os.path.join(project_root, "intent_classifier", "data", "confusion_intents.yml")
    config_path = os.path.join(project_root, "intent_classifier", "models", "confusion_config.yml")

    if not (os.path.exists(examples_path)):
        pytest.skip(f"Arquivos de dados de teste `confusion_intents.yml` nÃ£o encontrados em {examples_path}")
    if not (os.path.exists(config_path)):
        pytest.skip(f"Arquivos de configuraÃ§Ã£o `confusion_config.yml` nÃ£o encontrados em {config_path}")
        
    return {"config": config_path, "examples": examples_path}

@pytest.fixture(scope="module")
def clf_wandb(paths):
    """
    Fixture de integraÃ§Ã£o: Carrega o modelo real do W&B.
    - Pula (skip) se WANDB_MODELS ou WANDB_API_KEY nÃ£o estiverem definidos.
    - Falha (fail) se as secrets estiverem definidas, mas o modelo nÃ£o carregar.
    """
    load_dotenv()
    model_url = os.getenv("WANDB_MODELS", None)
    model_url = model_url.split(',')[0] if model_url else None
    api_key = os.getenv("WANDB_API_KEY")

    if not api_key:
        pytest.skip("WANDB_API_KEY nÃ£o definido. Pulando teste de integraÃ§Ã£o W&B.")
    if not model_url:
        pytest.skip("WANDB_MODELS nÃ£o definido. Pulando teste de integraÃ§Ã£o W&B.")

    print("\nðŸŒ WANDB_MODELS detectado, tentando carregar modelo real...")

    # A inicializaÃ§Ã£o tentarÃ¡ carregar o modelo
    classifier = IntentClassifier(config=paths["config"], 
                                training_data=paths["examples"],
                                load_model=model_url)
    
    # ValidaÃ§Ã£o crucial: o __init__ do cÃ³digo-fonte captura exceÃ§Ãµes e apenas imprime.
    # Devemos verificar ativamente se o modelo foi carregado.
    if classifier.model is None:
        pytest.fail(
            f"Secrets W&B definidas, mas o modelo falhou ao carregar de {model_url}. "
            "Verifique a API key, a URL do modelo ou se o modelo existe."
        )
        
    print(f"âœ… Modelo `{model_url}` carregado do W&B")
    return classifier

@pytest.fixture(scope="module")
def clf_local_trained(paths):
    """
    Fixture de sanidade: Treina um modelo pequeno localmente.
    Usa a sugestÃ£o de treinar com dados locais para um teste e2e.
    """
    print("\nâš™ï¸ Treinando modelo local para testes...")
    
    # ConfiguraÃ§Ã£o mÃ­nima para um treino rÃ¡pido
    local_config = Config(
        dataset_name="local_test",
        epochs=2,  # Apenas 2 Ã©pocas para velocidade
        callback_patience=1,
        validation_split=0.5,
        sent_hl_units=8,  # Modelo pequeno
    )
    
    # Passa o objeto Config e o caminho dos exemplos
    classifier = IntentClassifier(config=local_config, training_data=paths["examples"])
    classifier.train(tf_verbosity=0)  # Treina silenciosamente
    print("âœ… Modelo local treinado.")
    return classifier

@pytest.fixture
def clf_minimal():
    """Classificador leve, sem modelo, para testes de unidade rÃ¡pidos."""
    # Fornece 'codes' para satisfazer o _setup_encoder
    config = Config(
        dataset_name="minimal_test",
        min_words=2,
        codes=["intent_a", "intent_b"]
    )
    return IntentClassifier(config=config)

@pytest.fixture
def clf_with_stopwords(tmp_path):
    """Classificador leve com um arquivo de stopwords temporÃ¡rio."""
    # tmp_path Ã© uma fixture nativa do pytest
    stop_words_file = tmp_path / "stopwords.txt"
    stop_words_file.write_text("um\numa\nde\ndo")
    
    config = Config(
        dataset_name="stopwords_test",
        codes=["intent_a"],
        stop_words_file=str(stop_words_file)
    )
    return IntentClassifier(config=config)

# --- Testes de Unidade (RÃ¡pidos) ---

def test_init_fails_without_config_or_model(monkeypatch):
    """Verifica se a inicializaÃ§Ã£o falha se NENHUMA fonte de config/modelo for fornecida."""
    # monkeypatch Ã© uma fixture nativa do pytest para alterar o ambiente
    monkeypatch.delenv("WANDB_MODELS", raising=False)
    
    # Deve falhar, pois nem 'config', nem 'load_model', nem WANDB_MODELS foram dados
    with pytest.raises(ValueError, match="A 'config' must be provided"):
        IntentClassifier()

def test_preprocess_text_stopwords(clf_with_stopwords):
    """Testa a remoÃ§Ã£o de stopwords."""
    result_tensor = clf_with_stopwords.preprocess_text("uma frase de teste")
    assert result_tensor.numpy() == b'frase teste'

# --- Testes de Sanidade Local (MÃ©dios) ---

def test_local_train_model_created(clf_local_trained):
    """Verifica se o modelo local foi treinado e atribuÃ­do."""
    assert clf_local_trained.model is not None
    assert isinstance(clf_local_trained.model, tf.keras.Model)

def test_local_predict_sanity(clf_local_trained):
    """Testa a previsÃ£o (predict) usando o modelo treinado localmente."""
    clf = clf_local_trained
    top_intent, probs = clf.predict("oi como vai")
    
    assert isinstance(top_intent, str)
    assert top_intent in clf.codes
    assert isinstance(probs, dict)
    assert list(probs.keys()) == list(clf.codes)
    assert sum(probs.values()) == pytest.approx(1.0)

def test_one_hot_encoder_local(clf_local_trained):
    """Valida o one-hot encoder usando o modelo local treinado."""
    clf = clf_local_trained
    enc = clf.onehot_encoder
    codes = list(clf.codes)
    
    assert len(codes) > 1  # Garante que os dados de teste foram carregados
    
    for idx, code in enumerate(codes):
        vec = enc.transform([[code]]).toarray()[0]
        assert len(vec) == len(codes)
        assert vec[idx] == pytest.approx(1.0)
        assert ((vec == 0) | (vec == 1)).all()
        decoded = enc.inverse_transform([vec])[0][0]
        assert decoded == code

# --- Testes de IntegraÃ§Ã£o (Lentos) --- podem ser pulados se executar: `pytest -m "not integration"`

@pytest.mark.integration
def test_wandb_model_predicts(clf_wandb):
    """
    Teste de integraÃ§Ã£o real:
    Verifica se o modelo carregado do W&B consegue fazer uma previsÃ£o.
    """
    print("ðŸ”Ž Verificando a previsÃ£o (predict) do modelo do W&B")
    top_intent, probs = clf_wandb.predict("exemplo qualquer")
    
    print(f"IntenÃ§Ã£o prevista: {top_intent}")
    assert isinstance(top_intent, str)
    assert isinstance(probs, dict)
    assert len(probs) >= 1
    assert top_intent in clf_wandb.codes

@pytest.mark.integration
def test_wandb_model_accuracy_easy_examples(clf_wandb, paths):
    """
    Teste de integraÃ§Ã£o real:
    Verifica a acurÃ¡cia do modelo do W&B em exemplos conhecidos.
    """
    print("ðŸŒ Usando modelo do W&B para verificaÃ§Ã£o de acurÃ¡cia")
    
    with open(paths["examples"], "r") as f:
        data = yaml.safe_load(f)

    print(f"ðŸ“‚ Carregando exemplos de {paths['examples']}")
    samples = []
    for intent_block in data:
        for text in intent_block["examples"]:
            samples.append((text, intent_block["intent"]))
    
    # Pega uma amostra (mÃ¡x 50) para nÃ£o demorar muito
    samples = samples[:50] 
    texts = [t for t, _ in samples]
    labels = [l for _, l in samples]
    
    preds = clf_wandb.predict(texts)
    pred_labels = [p[0] for p in preds]

    accuracy = sum(p == l for p, l in zip(pred_labels, labels)) / len(labels)
    print(f"ðŸ† AcurÃ¡cia na amostra: {accuracy:.2f}")

    # RelatÃ³rio e Matriz de ConfusÃ£o
    report = classification_report(labels, pred_labels, zero_division=0)
    print("\nðŸ“„ RelatÃ³rio de ClassificaÃ§Ã£o (Amostra):\n" + report)

    all_labels = sorted(set(labels) | set(pred_labels))
    cm = confusion_matrix(labels, pred_labels, labels=all_labels)
    cm_df = pd.DataFrame(cm, index=all_labels, columns=all_labels)
    print("\nðŸ”¢ Matriz de ConfusÃ£o (Amostra):\n" + cm_df.to_string())

    # Define um limite de acurÃ¡cia razoÃ¡vel para o modelo de produÃ§Ã£o
    assert accuracy >= 0.7